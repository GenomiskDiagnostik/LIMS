.ai-provider-grid.ai-provider-params {
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
}
  ai_providers: ['id','name','provider_type','base_url','api_key','model','variant_pretext','variant_template','reasoning_effort','text_verbosity','max_output_tokens','temperature','top_p','logprobs','created_by','created_at','updated_at'],
const REASONING_EFFORT_VALUES = ['none','low','medium','high'];
const TEXT_VERBOSITY_VALUES = ['low','medium','high'];

function normaliseReasoningEffort(value) {
  const effort = (value || '').toLowerCase();
  return REASONING_EFFORT_VALUES.includes(effort) ? effort : 'none';
}

function normaliseTextVerbosity(value) {
  const verbosity = (value || '').toLowerCase();
  return TEXT_VERBOSITY_VALUES.includes(verbosity) ? verbosity : '';
}

function parseNumberInRange(value, {min = -Infinity, max = Infinity, round = false} = {}) {
  const num = Number(value);
  if (!Number.isFinite(num)) return null;
  if (num < min || num > max) return null;
  return round ? Math.round(num) : Number(num.toFixed(4));
}

function isGpt51Model(model) {
  const normalised = (model || '').toLowerCase();
  return normalised.startsWith('gpt-5.1');
}

function buildVariantAiPayload(provider, prompt) {
  const model = (provider?.model || '').trim();
  const reasoningEffort = normaliseReasoningEffort(provider?.reasoning_effort);
  const payload = {
    model,
    messages: [
      {role:'system', content: prompt.pretext},
      {role:'user', content: prompt.message}
    ]
  };
  if (reasoningEffort) {
    payload.reasoning = {effort: reasoningEffort};
  }
  const verbosity = normaliseTextVerbosity(provider?.text_verbosity);
  if (verbosity) {
    payload.text = {...(payload.text || {}), verbosity};
  }
  const maxTokens = parseNumberInRange(provider?.max_output_tokens, {min:1, round:true});
  if (maxTokens != null) {
    payload.max_output_tokens = maxTokens;
  }
  const allowSampling = isGpt51Model(model) && reasoningEffort === 'none';
  if (allowSampling) {
    const temperature = parseNumberInRange(provider?.temperature ?? 0.2, {min:0, max:2});
    const topP = parseNumberInRange(provider?.top_p, {min:0, max:1});
    const logprobs = parseNumberInRange(provider?.logprobs, {min:0, max:5, round:true});
    if (temperature != null) payload.temperature = temperature;
    if (topP != null) payload.top_p = topP;
    if (logprobs != null) payload.logprobs = logprobs;
  }
  return payload;
}

  const prompt = buildVariantPrompt(provider, formData);
  const payload = buildVariantAiPayload(provider, prompt);
          <div class="ai-provider-grid ai-provider-params">
            <label>Reasoning effort
              <select name="reasoning_effort">
                <option value="none" selected>none</option>
                <option value="low">low</option>
                <option value="medium">medium</option>
                <option value="high">high</option>
              </select>
            </label>
            <label>Output-verbosity
              <select name="text_verbosity">
                <option value="" selected>Standard</option>
                <option value="low">low</option>
                <option value="medium">medium</option>
                <option value="high">high</option>
              </select>
            </label>
            <label>Maks. output tokens<input type="number" name="max_output_tokens" min="1" step="1" placeholder="Fx 4000"></label>
            <label>Temperature<input type="number" name="temperature" min="0" max="2" step="0.05" placeholder="Fx 0.2"></label>
            <label>Top-p<input type="number" name="top_p" min="0" max="1" step="0.01" placeholder="Fx 1.0"></label>
            <label>Logprobs<input type="number" name="logprobs" min="0" max="5" step="1" placeholder="0-5"></label>
          </div>
          <p class="ai-provider-inline-hint">Temperature, top_p og logprobs må kun sendes til GPT-5.1 når reasoning effort er sat til "none"; andre GPT-5* kombinationer afviser forespørgslen.</p>
          <p class="ai-provider-inline-hint">Brug reasoning/verbosity/max_output_tokens for at styre længere eller mere detaljerede svar, især når reasoning effort er højere end none eller modellen ikke er GPT-5.1.</p>
      if (aiProviderForm.elements.reasoning_effort) {
        aiProviderForm.elements.reasoning_effort.value = provider.reasoning_effort || 'none';
      }
      if (aiProviderForm.elements.text_verbosity) {
        aiProviderForm.elements.text_verbosity.value = provider.text_verbosity || '';
      }
      ['temperature','top_p','logprobs','max_output_tokens'].forEach(field => {
        const control = aiProviderForm.elements[field];
        if (control) {
          control.value = provider[field] ?? '';
        }
      });
      if (aiProviderForm.elements.reasoning_effort) {
        aiProviderForm.elements.reasoning_effort.value = 'none';
      }
      if (aiProviderForm.elements.text_verbosity) {
        aiProviderForm.elements.text_verbosity.value = '';
      }
      ['temperature','top_p','logprobs','max_output_tokens'].forEach(field => {
        const control = aiProviderForm.elements[field];
        if (control) {
          control.value = '';
        }
      });
    data.reasoning_effort = normaliseReasoningEffort(data.reasoning_effort);
    const verbosity = normaliseTextVerbosity(data.text_verbosity);
    data.text_verbosity = verbosity || null;
    data.max_output_tokens = parseNumberInRange(data.max_output_tokens, {min:1, round:true});
    data.temperature = parseNumberInRange(data.temperature, {min:0, max:2});
    data.top_p = parseNumberInRange(data.top_p, {min:0, max:1});
    data.logprobs = parseNumberInRange(data.logprobs, {min:0, max:5, round:true});
  \`reasoning_effort\` VARCHAR(32),
  \`text_verbosity\` VARCHAR(32),
  \`max_output_tokens\` INT,
  \`temperature\` DECIMAL(4,2),
  \`top_p\` DECIMAL(4,3),
  \`logprobs\` INT,
